# MNIST Neural Network from Scratch (NumPy)

This project implements a simple neural network from scratch using **only NumPy**, trained on the MNIST handwritten digit dataset. No machine learning libraries used.

### Highlights
- Achieved **97.96% test accuracy**
- Fully implemented **forward & backward propagation**
- Used **ReLU**, **Softmax**, and **Cross Entropy Loss**
- Mini-batch **Gradient Descent** for training

### Dataset
- MNIST dataset (images of handwritten digits 0–9)
- Flattened 28x28 grayscale images to 784 input features

### Technologies
- Python
- NumPy
- Google Colab

---

### Files
- `mnist_nn_scratch.ipynb` – The full notebook with training and testing logic


