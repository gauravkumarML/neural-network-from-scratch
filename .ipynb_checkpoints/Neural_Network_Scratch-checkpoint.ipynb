{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "zvUKwoB80rQe",
    "ExecuteTime": {
     "end_time": "2025-05-21T14:02:44.283929Z",
     "start_time": "2025-05-21T14:02:44.151083Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "np.random.seed(42)"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdatasets\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m mnist\n\u001B[1;32m      4\u001B[0m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mseed(\u001B[38;5;241m42\u001B[39m)\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'keras'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "# load data, assign test and training set\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ],
   "metadata": {
    "id": "LQ7zkjoIhQxW",
    "ExecuteTime": {
     "end_time": "2025-05-21T14:02:45.597961Z",
     "start_time": "2025-05-21T14:02:45.586216Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mnist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# load data, assign test and training set\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m (x_train, y_train), (x_test, y_test) \u001B[38;5;241m=\u001B[39m \u001B[43mmnist\u001B[49m\u001B[38;5;241m.\u001B[39mload_data()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'mnist' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "# One-Hot Encode Vector\n",
    "\n",
    "def one_hot_encode(y, num_classes):\n",
    "    if y.ndim > 1 and y.shape[1] == num_classes: # Already one-hot encoded\n",
    "\n",
    "        return y\n",
    "    y = y.astype(int)\n",
    "    one_hot = np.zeros((y.shape[0], num_classes))\n",
    "    one_hot[np.arange(y.shape[0]), y] = 1\n",
    "    return one_hot\n",
    "\n",
    "x_train = x_train.reshape(-1, 28*28) / 255.0\n",
    "x_test = x_test.reshape(-1, 28*28) / 255.0\n",
    "\n",
    "y_train = one_hot_encode(y_train, 10)\n",
    "y_test = one_hot_encode(y_test, 10)\n",
    "\n",
    "\n",
    "print(f\"Training samples: {x_train.shape[0]}, Test samples: {x_test.shape[0]}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kSiC3FefhZky",
    "outputId": "75468664-2423-4e66-8541-9898044259d5",
    "ExecuteTime": {
     "end_time": "2025-05-21T13:57:34.310487Z",
     "start_time": "2025-05-21T13:57:34.233313Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 12\u001B[0m\n\u001B[1;32m      9\u001B[0m     one_hot[np\u001B[38;5;241m.\u001B[39marange(y\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]), y] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m one_hot\n\u001B[0;32m---> 12\u001B[0m x_train \u001B[38;5;241m=\u001B[39m \u001B[43mx_train\u001B[49m\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m28\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m28\u001B[39m) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m255.0\u001B[39m\n\u001B[1;32m     13\u001B[0m x_test \u001B[38;5;241m=\u001B[39m x_test\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m28\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m28\u001B[39m) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m255.0\u001B[39m\n\u001B[1;32m     15\u001B[0m y_train \u001B[38;5;241m=\u001B[39m one_hot_encode(y_train, \u001B[38;5;241m10\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "# Initialization and Forward Propagation set up\n",
    "\n",
    "def initialize_parameters(input_size, hidden_size, output_size):\n",
    "    W1 = np.random.randn(input_size, hidden_size) * 0.01\n",
    "    b1 = np.zeros((1, hidden_size))\n",
    "\n",
    "    W2 = np.random.randn(hidden_size, output_size) * 0.01\n",
    "    b2 = np.zeros((1, output_size))\n",
    "\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def ReLU(Z):\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def softmax(Z):\n",
    "    exp_Z = np.exp(Z - np.max(Z, axis=1, keepdims=True))\n",
    "    return exp_Z / np.sum(exp_Z, axis=1, keepdims=True)\n",
    "\n",
    "def forward_prop(X, W1, b1, W2, b2):\n",
    "    Z1 = np.dot(X, W1) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "\n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    A2 = softmax(Z2)\n",
    "\n",
    "    return A1, A2\n",
    "\n"
   ],
   "metadata": {
    "id": "hyP8vYBmhce1"
   },
   "execution_count": 71,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cross Entropy Loss\n",
    "\n",
    "def compute_loss(A2, Y):\n",
    "    m = Y.shape[0]\n",
    "    loss = -np.sum(Y * np.log(A2)) / m\n",
    "    return loss\n",
    "\n",
    "# Backward Propagation\n",
    "\n",
    "def backward_prop(X, Y, A1, A2, W1, W2):\n",
    "    n = X.shape[0]\n",
    "\n",
    "    # Output layer (Layer 2)\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = np.dot(A1.T, dZ2) / n\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True) / n\n",
    "\n",
    "    # Hidden layer (Layer 1)\n",
    "    dA1 = np.dot(dZ2, W2.T)\n",
    "    dZ1 = dA1 * (A1 > 0)\n",
    "    dW1 = np.dot(X.T, dZ1) / n\n",
    "    db1 = np.sum(dZ1, axis=0, keepdims=True) / n\n",
    "\n",
    "    gradients = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n",
    "\n",
    "    return gradients\n",
    "\n",
    "\n",
    "# Gradient Descent\n",
    "\n",
    "def update_parameters(W1, b1, W2, b2, gradients, learning_rate):\n",
    "    W1 -= learning_rate * gradients[\"dW1\"]\n",
    "    b1 -= learning_rate * gradients[\"db1\"]\n",
    "    W2 -= learning_rate * gradients[\"dW2\"]\n",
    "    b2 -= learning_rate * gradients[\"db2\"]\n",
    "\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "# Showdown Training Function\n",
    "def train(X_train, Y_train, epochs, learning_rate, batch_size):\n",
    "    input_size = X_train.shape[1]   # 784\n",
    "    output_size = Y_train.shape[1]  # 10\n",
    "    hidden_size = 128\n",
    "\n",
    "    # Initialize parameters\n",
    "    W1, b1, W2, b2 = initialize_parameters(input_size, hidden_size, output_size)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "\n",
    "        # Mini-batch gradient descent\n",
    "        for i in range(0, X_train.shape[0], batch_size):\n",
    "            X_batch = X_train[i:i+batch_size]\n",
    "            Y_batch = Y_train[i:i+batch_size]\n",
    "\n",
    "            # Forward propagation\n",
    "            A1, A2 = forward_prop(X_batch, W1, b1, W2, b2)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = compute_loss(A2, Y_batch)\n",
    "            epoch_loss += loss\n",
    "\n",
    "            # Backpropagation\n",
    "            gradients = backward_prop(X_batch, Y_batch, A1, A2, W1, W2)\n",
    "\n",
    "            # Update parameters\n",
    "            W1, b1, W2, b2 = update_parameters(W1, b1, W2, b2, gradients, learning_rate)\n",
    "\n",
    "        # Print the loss after 10th cycle\n",
    "        if epoch % 10 == 0:\n",
    "          epoch_loss /= (X_train.shape[0] // batch_size)\n",
    "          print(f\"Epoch {epoch + 1}, Loss: {epoch_loss}\")\n",
    "\n",
    "\n",
    "\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "\n",
    "W1, b1, W2, b2 = train(x_train, y_train, epochs=100, learning_rate=0.1, batch_size=128)\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bm3Yz0Ta0j5-",
    "outputId": "160b4fab-b8e6-4b22-bf4d-a4c9fbc5191a"
   },
   "execution_count": 88,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Loss: 0.7621555852758589\n",
      "Epoch 11, Loss: 0.1085190529670415\n",
      "Epoch 21, Loss: 0.05917797491991317\n",
      "Epoch 31, Loss: 0.03796906332325583\n",
      "Epoch 41, Loss: 0.02588089469058749\n",
      "Epoch 51, Loss: 0.018355095971199553\n",
      "Epoch 61, Loss: 0.013445087197368744\n",
      "Epoch 71, Loss: 0.01017335552564088\n",
      "Epoch 81, Loss: 0.007903629135833482\n",
      "Epoch 91, Loss: 0.006295570847423308\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def predict(X, W1, b1, W2, b2):\n",
    "    _, A2 = forward_prop(X, W1, b1, W2, b2)\n",
    "    return np.argmax(A2, axis=1)\n",
    "\n",
    "y_pred = predict(x_test, W1, b1, W2, b2)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "accuracy = np.mean(y_pred == y_true)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "clPgSzHF3JCp",
    "outputId": "b3e0400b-4311-4641-a37a-a19584793a91"
   },
   "execution_count": 89,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Accuracy: 97.96%\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ---- export trained parameters ----\n",
    "import numpy as np, pickle, pathlib\n",
    "\n",
    "params = {\n",
    "    \"W1\": W1, \"b1\": b1,\n",
    "    \"W2\": W2, \"b2\": b2,\n",
    "    # add deeper layers if you have them\n",
    "}\n",
    "pathlib.Path(\"model\").mkdir(exist_ok=True)\n",
    "np.savez(\"model/mnist_scratch_weights.npz\", **params)\n",
    "print(\"✅  Saved weights → model/mnist_scratch_weights.npz\")\n"
   ],
   "metadata": {
    "id": "2HOehhteILd9",
    "ExecuteTime": {
     "end_time": "2025-05-21T14:05:49.691727Z",
     "start_time": "2025-05-21T14:05:49.664826Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'W1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# ---- export trained parameters ----\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\u001B[38;5;241m,\u001B[39m \u001B[38;5;21;01mpickle\u001B[39;00m\u001B[38;5;241m,\u001B[39m \u001B[38;5;21;01mpathlib\u001B[39;00m\n\u001B[1;32m      4\u001B[0m params \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m----> 5\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mW1\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[43mW1\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb1\u001B[39m\u001B[38;5;124m\"\u001B[39m: b1,\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mW2\u001B[39m\u001B[38;5;124m\"\u001B[39m: W2, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb2\u001B[39m\u001B[38;5;124m\"\u001B[39m: b2,\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;66;03m# add deeper layers if you have them\u001B[39;00m\n\u001B[1;32m      8\u001B[0m }\n\u001B[1;32m      9\u001B[0m pathlib\u001B[38;5;241m.\u001B[39mPath(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mmkdir(exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     10\u001B[0m np\u001B[38;5;241m.\u001B[39msavez(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel/mnist_scratch_weights.npz\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'W1' is not defined"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T14:09:01.394631Z",
     "start_time": "2025-05-21T14:09:01.370641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()   # should download & load\n",
    "print(x_train.shape, y_train[:5])"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdatasets\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m mnist\n\u001B[1;32m      2\u001B[0m (x_train, y_train), (x_test, y_test) \u001B[38;5;241m=\u001B[39m mnist\u001B[38;5;241m.\u001B[39mload_data()   \u001B[38;5;66;03m# should download & load\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(x_train\u001B[38;5;241m.\u001B[39mshape, y_train[:\u001B[38;5;241m5\u001B[39m])\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'keras'"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
